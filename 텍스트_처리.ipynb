{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPr8sgBrInwwiY+A8OznnO5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ara42/Deep-Learning/blob/main/%ED%85%8D%EC%8A%A4%ED%8A%B8_%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRecEKmaf1Yg",
        "outputId": "0cfa6e57-265a-4dcb-a544-d0ea96866b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  7897k      0  0:00:10  0:00:10 --:--:-- 17.2M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "id": "fhF5pqA7gBIG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "l97U7VlmgCZg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os ,pathlib, shutil,random"
      ],
      "metadata": {
        "id": "hT7pOpqSgDhv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = pathlib.Path('aclImdb')\n",
        "val_dir = base_dir/\"val\"\n",
        "train_dir = base_dir/\"train\"\n",
        "for category in (\"neg\",\"pos\"):\n",
        "  os.makedirs(val_dir/category)\n",
        "  files = os.listdir(train_dir/category)\n",
        "  random.Random(1337).shuffle(files)\n",
        "  num_val_samples = int(0.2*len(files))\n",
        "  val_files = files[:num_val_samples]\n",
        "  for fname in val_files:\n",
        "    shutil.move(train_dir/category/fname,\n",
        "                val_dir/category/fname)"
      ],
      "metadata": {
        "id": "Dwcxd8NpgEu4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "0KmYAl-AgGzt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = keras.utils.text_dataset_from_directory('aclImdb/train',\n",
        "                                                   batch_size=32)\n",
        "val_ds = keras.utils.text_dataset_from_directory('aclImdb/val',\n",
        "                                                   batch_size=32)\n",
        "test_ds = keras.utils.text_dataset_from_directory('aclImdb/test',\n",
        "                                                   batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0NjkV2-gH7D",
        "outputId": "59437aa0-2a90-46c7-a550-bf4332c33d03"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시퀀스"
      ],
      "metadata": {
        "id": "jWhHEbGrgKQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers"
      ],
      "metadata": {
        "id": "CTnDrnehgJf1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 600\n",
        "max_tokens = 20000"
      ],
      "metadata": {
        "id": "sj873RP2gR5J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x,y: x)\n",
        "\n",
        "tv.adapt(text_only_train_ds) #vacabulary 형성"
      ],
      "metadata": {
        "id": "3piGYgBjg2ba"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_train_ds = train_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")"
      ],
      "metadata": {
        "id": "cuGdAm0Vg4JD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "naVj7K0MiX_8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,),dtype='int64')\n",
        "embedded = tf.one_hot(inputs,depth=max_tokens)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "model = keras.Model(inputs,outputs)\n",
        "model.compile(loss=keras.losses.binary_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zw01kBqwiaie"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RAM 부족(실행X)\n",
        "mcp = keras.callbacks.ModelCheckpoint('one_hot_bidir_lstm.keras',\n",
        "                                      save_best_only=True)\n",
        "model.fit(int_train_ds.cache(),\n",
        "          validation_data=int_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=[mcp])\n",
        "model = keras.models.load_model('one_hot_bidir_lstm.keras')\n",
        "model.evaluate(int_test_ds)"
      ],
      "metadata": {
        "id": "teT6LTB3jZfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,),dtype='int64')\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "model = keras.Model(inputs,outputs)\n",
        "model.compile(loss=keras.losses.binary_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JOVv12E3kVmq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcp = keras.callbacks.ModelCheckpoint('embedding_bidir_lstm.keras',\n",
        "                                      save_best_only=True)\n",
        "model.fit(int_train_ds.cache(),\n",
        "          validation_data=int_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=[mcp])\n",
        "model = keras.models.load_model('embedding_bidir_lstm.keras')\n",
        "model.evaluate(int_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuNO_CtqkoPr",
        "outputId": "df260277-116e-4cc0-e9c8-186f0c9266fb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 109s 160ms/step - loss: 0.5176 - accuracy: 0.7452 - val_loss: 0.4146 - val_accuracy: 0.8308\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 23s 37ms/step - loss: 0.3582 - accuracy: 0.8662 - val_loss: 0.3340 - val_accuracy: 0.8664\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 23s 36ms/step - loss: 0.2871 - accuracy: 0.8946 - val_loss: 0.3223 - val_accuracy: 0.8800\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.2393 - accuracy: 0.9172 - val_loss: 0.3881 - val_accuracy: 0.8608\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.2123 - accuracy: 0.9304 - val_loss: 0.3778 - val_accuracy: 0.8734\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.1780 - accuracy: 0.9427 - val_loss: 0.3813 - val_accuracy: 0.8740\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 0.1740 - accuracy: 0.9437 - val_loss: 0.4722 - val_accuracy: 0.8378\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.1480 - accuracy: 0.9546 - val_loss: 0.4264 - val_accuracy: 0.8692\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.1198 - accuracy: 0.9639 - val_loss: 0.5035 - val_accuracy: 0.8324\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.1088 - accuracy: 0.9672 - val_loss: 0.4411 - val_accuracy: 0.8704\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 0.3483 - accuracy: 0.8660\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3482641279697418, 0.8660399913787842]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FIKUxCRxlTpS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}